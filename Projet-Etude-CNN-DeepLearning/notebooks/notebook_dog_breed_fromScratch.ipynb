{
 "cells": [
  {
   "cell_type": "code",
   "id": "c56c5065-4383-4b48-9d4c-d602799a44e2",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import mixed_precision"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Benchmark",
   "id": "e127a526c6aa333"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _():\n",
    "    # --- FONCTION DE TEST ---\n",
    "    def benchmark(device_name, steps=10):\n",
    "        print(f\"\\n--- Test sur {device_name} en cours... ---\")\n",
    "        with tf.device(device_name):\n",
    "            # Cr√©ation d'un mod√®le factice\n",
    "            model_benchmark = MobileNetV2(weights=None, input_shape=(224, 224, 3), classes=120)\n",
    "            model_benchmark.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "            # Donn√©es factices\n",
    "            fake_data = np.random.random((16, 224, 224, 3)).astype('float32')\n",
    "            fake_labels = np.random.random((16, 120)).astype('float32')\n",
    "\n",
    "            # Chauffe (Warm-up)\n",
    "            model_benchmark.train_on_batch(fake_data, fake_labels)\n",
    "\n",
    "            # Mesure\n",
    "            start = time.time()\n",
    "            for _ in range(steps):\n",
    "                model_benchmark.train_on_batch(fake_data, fake_labels)\n",
    "            end = time.time()\n",
    "\n",
    "            avg_time = (end - start) / steps\n",
    "            print(f\"‚è±Ô∏è Temps moyen par batch : {avg_time*1000:.1f} ms\")\n",
    "            return avg_time\n",
    "\n",
    "    # --- R√âSULTATS ---\n",
    "    t_cpu = benchmark('/CPU:0')\n",
    "    t_gpu = benchmark('/GPU:0')\n",
    "\n",
    "    print(f\"\\nüöÄ ACC√âL√âRATION : Le GPU est {t_cpu/t_gpu:.1f}x plus rapide que le CPU !\")\n",
    "\n",
    "# _()"
   ],
   "id": "6db282973cf42c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Environnement",
   "id": "20d5d4c522149d09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "ROOT_DIRECTORY = Path.cwd().parent.parent\n",
    "ETUDE_DIRECTORY = ROOT_DIRECTORY / 'Projet-Etude-CNN-DeepLearning'\n",
    "DATASET_DIRECTORY = ETUDE_DIRECTORY / \"dataset\" / \"Dog-Breed-Identification\"\n",
    "NOTEBOOKS_DIRECTORY = ETUDE_DIRECTORY / \"notebooks\"\n",
    "MODELS_DIRECTORY = ETUDE_DIRECTORY / \"models\"\n",
    "\n",
    "TRAIN_DATASET_FOLDER_JPG = DATASET_DIRECTORY / 'train'\n",
    "TEST_DATASET_FOLDER_JPG = DATASET_DIRECTORY / 'test'\n",
    "FEATURES_FILE_CSV = DATASET_DIRECTORY / 'labels.csv'\n",
    "\n",
    "MODEL_NAME = \"model_dog_from_scratch\"\n",
    "MODEL_CHECKPOINT_PATH = MODELS_DIRECTORY / MODEL_NAME / 'checkpoints' / f\"{MODEL_NAME}_checkpoint.keras\"\n",
    "MODEL_FINAL_PATH = MODELS_DIRECTORY / MODEL_NAME / f\"{MODEL_NAME}.keras\"\n",
    "\n",
    "print(f\"\"\"\n",
    "ROOT_DIRECTORY : {ROOT_DIRECTORY}\n",
    "ETUDE_DIRECTORY : {ETUDE_DIRECTORY}\n",
    "DATASET_DIRECTORY : {DATASET_DIRECTORY}\n",
    "NOTEBOOKS_DIRECTORY : {NOTEBOOKS_DIRECTORY}\n",
    "MODELS_DIRECTORY : {MODELS_DIRECTORY}\n",
    "TRAIN_DATASET_FOLDER_JPG : {TRAIN_DATASET_FOLDER_JPG}\n",
    "TEST_DATASET_FOLDER_JPG : {TEST_DATASET_FOLDER_JPG}\n",
    "FEATURES_FILE_CSV : {FEATURES_FILE_CSV}\n",
    "MODEL_NAME : {MODEL_NAME}\n",
    "MODEL_CHECKPOINT_PATH: {MODEL_CHECKPOINT_PATH}\n",
    "MODEL_FINAL_PATH : {MODEL_FINAL_PATH}\n",
    "\"\"\")"
   ],
   "id": "a72ccec22524c44b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration mat√©rielle",
   "id": "82b4455d6f52d8ae"
  },
  {
   "cell_type": "code",
   "id": "bd2445d5-4a31-44aa-8899-2df9aa19481d",
   "metadata": {},
   "source": [
    "def show_available_configuration():\n",
    "    \"\"\"\n",
    "    Show the current hardware configuration\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(f\"üêç Version Python : {sys.version.split()[0]}\")\n",
    "    print(f\"ü§ñ Version TensorFlow : {tf.__version__}\")\n",
    "\n",
    "    try:\n",
    "        print(\"\\n--- √âtat Syst√®me (nvidia-smi) ---\")\n",
    "        !nvidia-smi\n",
    "    except Exception as rised_error:\n",
    "        print(rised_error)\n",
    "\n",
    "    print(\"\\n--- D√©tection TensorFlow ---\")\n",
    "    if not gpus:\n",
    "        print(\"‚ùå Aucun GPU d√©tect√© par TensorFlow.\")\n",
    "        print(\"Causes possibles :\")\n",
    "        print(\"1. Vous n'avez pas install√© 'tensorflow[and-cuda]'\")\n",
    "        print(\"2. Votre version de Python n'est pas support√©e.\")\n",
    "        print(\"3. La variable CUDA_VISIBLE_DEVICES = -1 est rest√©e active.\")\n",
    "    else:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"‚úÖ GPU configur√© : M√©moire dynamique activ√©e\")\n",
    "        except RuntimeError as rised_error:\n",
    "            print(f\"Erreur config GPU : {rised_error}\")\n",
    "\n",
    "show_available_configuration()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chargement des donn√©es",
   "id": "f10c393b77c5d5b6"
  },
  {
   "cell_type": "code",
   "id": "0808a687-a47f-422a-ab8e-341bb51e5652",
   "metadata": {},
   "source": [
    "images_train_dataset = os.listdir(TRAIN_DATASET_FOLDER_JPG)\n",
    "images_test_dataset = os.listdir(TEST_DATASET_FOLDER_JPG)\n",
    "labels_df = pd.read_csv(FEATURES_FILE_CSV)\n",
    "print(' No# of train images in data:', len(images_train_dataset))\n",
    "print(' No# of test images in data:', len(images_test_dataset))\n",
    "labels_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Affichage des images du dataset",
   "id": "30332a733dba0669"
  },
  {
   "cell_type": "code",
   "id": "4887d40c-f15e-49e5-8560-1f2fc2c51218",
   "metadata": {},
   "source": [
    "def display_n_images(dataset, n):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(n):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        # 1. R√©cup√©rer le nom du fichier\n",
    "        filename = dataset[i]\n",
    "        # 2. Construire le chemin complet vers l'image\n",
    "        img_path = os.path.join(TRAIN_DATASET_FOLDER_JPG, filename)\n",
    "        # 3. Charger l'image r√©elle (les pixels)\n",
    "        img = mpimg.imread(img_path)\n",
    "        # 4. Afficher l'image\n",
    "        plt.imshow(img)\n",
    "        # 5. R√©cup√©rer le label correct\n",
    "        img_id = filename.split('.')[0]\n",
    "        plt.grid(False)\n",
    "        plt.axis('off')\n",
    "        try:\n",
    "            label = labels_df.loc[labels_df['id'] == img_id, 'breed']\n",
    "        except IndexError:\n",
    "            label = \"Inconnu\"\n",
    "        plt.xlabel(label, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_n_images(images_train_dataset, 10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variables de Configuration",
   "id": "f986119512a19da8"
  },
  {
   "cell_type": "code",
   "id": "88c8cb1e-880c-4c82-9ba3-40aaeabdae1a",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 16\n",
    "RANDOM_SEED = 42\n",
    "SHUFFLE = True\n",
    "TARGET_SIZE = (224,224)\n",
    "\n",
    "VALIDATION_SPLIT = 0.2      # 20% des donn√©es serviront √† la validation\n",
    "ROTATION_RANGE = 40         # Rotation al√©atoire jusqu'√† 20 degr√©s\n",
    "WIDTH_SHIFT_RANGE = 0.2     # D√©calage horizontal\n",
    "HEIGHT_SHIFT_RANGE = 0.2    # D√©calage vertical\n",
    "HORIZONTAL_FLIP = True      # Retournement horizontal (miroir)\n",
    "FILL_MODE = \"nearest\"       # Methode de remplissage des pixels \"√©teints\"\n",
    "\n",
    "# Reconstitution des noms des fichiers d'images\n",
    "labels_df['id'] = labels_df['id'].apply(lambda x: x + \".jpg\" if not x.endswith(\".jpg\") else x)\n",
    "\n",
    "# print(labels_df.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration de l'entra√Ænement",
   "id": "9a2cf2b6f9285ec5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cr√©ation du g√©n√©rateur avec augmentation de donn√©es\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "# Configuration pour l'entra√Ænement avec augmentation de donn√©es\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    rotation_range=ROTATION_RANGE,\n",
    "    width_shift_range=WIDTH_SHIFT_RANGE,\n",
    "    height_shift_range=HEIGHT_SHIFT_RANGE,\n",
    "    horizontal_flip=HORIZONTAL_FLIP,\n",
    "    fill_mode=FILL_MODE\n",
    ")\n",
    "\n",
    "# Configuration pour la validation\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Entra√Ænement\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory=TRAIN_DATASET_FOLDER_JPG,\n",
    "    x_col=\"id\",\n",
    "    y_col=\"breed\",\n",
    "    subset=\"training\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=RANDOM_SEED,\n",
    "    shuffle=SHUFFLE,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=TARGET_SIZE\n",
    ")\n",
    "\n",
    "# Validation\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory=TRAIN_DATASET_FOLDER_JPG,\n",
    "    x_col=\"id\",\n",
    "    y_col=\"breed\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=RANDOM_SEED,\n",
    "    shuffle=SHUFFLE,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=TARGET_SIZE\n",
    ")\n",
    "\n",
    "# ---- Configuration du d√©roulement de l'entra√Ænement ----\n",
    "# 1. Sauvegarde\n",
    "checkpoint = ModelCheckpoint(MODEL_CHECKPOINT_PATH,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)\n",
    "\n",
    "# 2. Arr√™t automatique (Patience augment√©e √† 8, car l'apprentissage from scratch est lent)\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=8,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "# 3. Ralentissement automatique (INDISPENSABLE ici)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,    # On divise le Learning Rate par 5\n",
    "                              patience=3,    # Si pas d'am√©lioration pendant 3 √©poques\n",
    "                              min_lr=1e-6,   # Ne pas descendre trop bas\n",
    "                              verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stop, reduce_lr]\n",
    "\n",
    "# print(train_generator.class_indices)"
   ],
   "id": "fa2142ce8f9c7a3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Architecture du mod√®le",
   "id": "8286e3aa60a3a5ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$Convolution : Sortie = (Poids √ó Entr√©e) + Biais_conv$\n",
    "\n",
    "Si on utilise un biais dans la convolution :\n",
    "\n",
    "$(x + Biais_conv) ‚àí Moyenne = (x ‚àí Moyenne) + (Biais_conv ‚àí Biais_conv)$\n",
    "\n",
    "Encha√Ænement d'op√©rations :\n",
    "- Conv2D : Extraction des caract√©ristiques (Calcul lourd).\n",
    "- BatchNormalization : Stabilisation et recentrage (Pr√©pare les donn√©es).\n",
    "- Activation (ReLU) : D√©cision non-lin√©aire (Garde l'info utile, jette le reste).\n",
    "- Dropout / Pooling : R√©gularisation ou r√©duction de dimension."
   ],
   "id": "13db3eb841256e4f"
  },
  {
   "cell_type": "code",
   "id": "ac931a17-987e-4b85-83fe-759463bab2b7",
   "metadata": {},
   "source": [
    "N_CLASSES = len(train_generator.class_indices)\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "METRICS = ['accuracy']\n",
    "LOSS = 'categorical_crossentropy'\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "def build_advanced_model(input_shape, n_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # --- BLOC SQUEEZE-EXCITATION (Attention) ---\n",
    "    def se_block(x_se, filters, ratio=16):\n",
    "        # R√©duit l'image √† 1x1 pixel par canal (moyenne g√©n√©rale)\n",
    "        se = layers.GlobalAveragePooling2D()(x_se)\n",
    "        # Compression\n",
    "        se = layers.Dense(filters // ratio, activation='relu', use_bias=False)(se)\n",
    "        # √âtirement et application de sigmoid (poids entre 0 et 1)\n",
    "        se = layers.Dense(filters, activation='sigmoid', use_bias=False)(se)\n",
    "        # Canaux d'origine * poids\n",
    "        return layers.Multiply()([x_se, se])\n",
    "\n",
    "    # --- BLOC R√âSIDUEL COMPLET ---\n",
    "    def res_conv_block(x_res, filters, stride=1):\n",
    "        shortcut = x_res\n",
    "        # 1. Gestion du raccourci (Shortcut)\n",
    "        if stride > 1 or x_res.shape[-1] != filters:\n",
    "            shortcut = layers.Conv2D(\n",
    "                filters,\n",
    "                (1, 1),\n",
    "                strides=stride,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizers.l2(1e-4))(x_res)\n",
    "\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        # 2. Branche principale (Convolution A)\n",
    "        x_res = layers.Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            strides=stride,\n",
    "            padding='same',\n",
    "            use_bias=False,\n",
    "            kernel_regularizer=regularizers.l2(1e-4))(x_res)\n",
    "\n",
    "        x_res = layers.BatchNormalization()(x_res)\n",
    "        x_res = layers.Activation('swish')(x_res)\n",
    "        # 3. Branche principale (Convolution B)\n",
    "        x_res = layers.Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding='same',\n",
    "            use_bias=False,\n",
    "            kernel_regularizer=regularizers.l2(1e-4))(x_res)\n",
    "\n",
    "        x_res = layers.BatchNormalization()(x_res)\n",
    "        # 4. Int√©gration de l'Attention (SE Block)\n",
    "        x_res = se_block(x_res, filters)\n",
    "        # 5. Skip Connection\n",
    "        x_res = layers.Add()([x_res, shortcut])\n",
    "        x_res = layers.Activation('swish')(x_res) # Activation finale du bloc\n",
    "\n",
    "        return x_res\n",
    "\n",
    "    # --- D√âBUT DE L'ARCHITECTURE ---\n",
    "    # Convolution initiale\n",
    "    x = layers.Conv2D(32, (3, 3), strides=1, padding='same', use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    # --- EMPILEMENT DES BLOCS ---\n",
    "    x = res_conv_block(x, 64, stride=2)   # R√©duit la taille /2\n",
    "    x = res_conv_block(x, 64, stride=1)   # Garde la taille (plus de profondeur)\n",
    "\n",
    "    x = res_conv_block(x, 128, stride=2)\n",
    "    x = res_conv_block(x, 128, stride=1)\n",
    "\n",
    "    x = res_conv_block(x, 256, stride=2)\n",
    "    x = res_conv_block(x, 256, stride=1)\n",
    "\n",
    "    x = res_conv_block(x, 512, stride=2)\n",
    "    x = res_conv_block(x, 512, stride=1)\n",
    "\n",
    "    # --- T√äTE DU R√âSEAU ---\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(\n",
    "        n_classes,\n",
    "        activation='softmax'\n",
    "    )(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Cr√©ation\n",
    "model = build_advanced_model(INPUT_SHAPE, N_CLASSES)\n",
    "\n",
    "# Compilation\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss=LOSS,\n",
    "              metrics=METRICS)\n",
    "\n",
    "# model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Entra√Ænement du mod√®le",
   "id": "363fb584c03696ef"
  },
  {
   "cell_type": "code",
   "id": "29e66a6b-f994-4957-92e8-e159ac7ef315",
   "metadata": {},
   "source": [
    "# 4. Lancement (50 EPOCHS)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    callbacks=callbacks_list\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualisation du d√©roulement de l'entra√Ænement",
   "id": "1e944febacd1045b"
  },
  {
   "cell_type": "code",
   "id": "88a9b353-437a-42d8-8a80-0eae3f7ee00f",
   "metadata": {},
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Courbe de Pr√©cision\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Entra√Ænement Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Pr√©cision (Accuracy)')\n",
    "\n",
    "# Courbe de Perte\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Entra√Ænement Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Perte (Loss)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sauvegarde du mod√®le",
   "id": "fb5f536aa320e668"
  },
  {
   "cell_type": "code",
   "id": "634fb6d9-4890-42cd-9947-6cb0ea0b3304",
   "metadata": {},
   "source": [
    "# Sauvegarde au format de Keras\n",
    "model.save(MODEL_FINAL_PATH)\n",
    "print(\"Mod√®le sauvegard√© avec succ√®s !\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test de pr√©diction",
   "id": "6c2960a6cdc0cfa7"
  },
  {
   "cell_type": "code",
   "id": "efbff3be-a4b9-4bd9-b7e8-a07992d8ef85",
   "metadata": {},
   "source": [
    "labels_map = {v: k for k, v in train_generator.class_indices.items()}\n",
    "\n",
    "def predict_breed(img_path):\n",
    "    # Charger l'image et la redimensionner comme √† l'entra√Ænement (224x224)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    # Convertir en tableau de nombres (array)\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # Normaliser (diviser par 255 comme lors de l'entra√Ænement)\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Ajouter une dimension pour simuler un batch de 1 image (1, 224, 224, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Faire la pr√©diction\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    # Trouver l'index de la probabilit√© la plus √©lev√©e\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    confidence = np.max(predictions) * 100\n",
    "    \n",
    "    predicted_breed = labels_map[predicted_class_index]\n",
    "    \n",
    "    # Affichage\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Pr√©diction : {predicted_breed} ({confidence:.2f}%)\")\n",
    "    plt.show()\n",
    "\n",
    "# --- UTILISATION ---\n",
    "# Remplacez par le chemin d'une image de votre dossier de test\n",
    "test_image_path = os.path.join(TEST_DATASET_FOLDER_JPG, os.listdir(TEST_DATASET_FOLDER_JPG)[3])\n",
    "predict_breed(test_image_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dump des labels\n",
    "Utilis√© ensuite depuis l'application web afin de relier les ID aux labels"
   ],
   "id": "5fabd71e543bb2c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# R√©cup√©rer le mapping ({'beagle': 0, 'boxer': 1})\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Inverser pour avoir {0: 'beagle', 1: 'boxer'}\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Sauvegarder dans un fichier\n",
    "with open(DATASET_DIRECTORY / 'class_indices.json', 'w') as f:\n",
    "    json.dump(idx_to_class, f)\n",
    "\n",
    "print(\"‚úÖ Fichier class_indices.json g√©n√©r√© !\")"
   ],
   "id": "b2c28c0d8ae5125",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
